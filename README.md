# Explainable AI (XAI)
Explainable AI Report in ML Course (Reichman University)
by Idan Kashtan

<img src="dog_explanation.jpg" alt="Dog explanation" width="400"/>

Most of the time, we need more than just the prediction of our model. We want to explain why the model thinks that way and use this explanation in several ways. First, we can take our explanation and give it to the end-users for them to understand the prediction. Second, we need it as developers and researchers so we can debug our model and make it better. Third, the decision-makers should base their decisions on that explanation and regulators. We have a few types of XAI, Global and local explanations, model-based, post-hoc, black and white box models.
In this report, I focus on LIME and how I implemented it.

This repository includes the following:
* The report document with my analysis (pdf)
* One notebook with my implementation, testing, and results

## Results
Detailed results can be found in the report under:
* "More examples"

### For the dataset
You can use any image as long you use Alexnet.
